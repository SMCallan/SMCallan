# Callan Smith MacDonald

> A technologist operating at the nexus of software engineering, cyber security, and digital ethics. My focus is on architecting resilient systems and developing strategies that account for the most complex variable: human behaviour.

[<img src="https://img.shields.io/badge/Website-computerscience.engineer-blue?style=for-the-badge&logo=data:image/svg+xml;base64,PHN2ZyBmaWxsPSIjRkZGRkZGIiByb2xlPSJpbWciIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48dGl0bGU+R2xvYmU8L3RpdGxlPjxwYXRoIGQ9Ik0xMiAwYTExLjk5IDEyIDAgMCAwLTEyIDEyYTExLjk5IDEyIDAgMCAwIDEyIDEyIDEyIDEyIDAgMCAwIDAtMjRtMCAyMC44MmE4LjgzIDguODMgMCAwIDEtOC44Mi04LjgzQTguODMgOC44MyAwIDAgMSAxMiAzLjEzYTguODIgOC44MiAwIDAgMSA4LjgyIDguODMgOC44MyA4LjgzIDAgMCAxLTguODIgOC44M1oiLz48cGF0aCBkPSJNMTIgMGEyOC44OCAyOC44OCAwIDAgMC0xLjc0IDI0aDMuNDhBMTguOTEgMTguOTEgMCAwIDAgMTIgMFoiLz48L3N2Zz4=" />](https://computerscience.engineer/)

---

### Core Domains of Practice

My work is centered on three interconnected domains:

1.  **Secure Systems Engineering**
    * I build defensible and resilient software with a security-first methodology. This involves full-lifecycle threat modeling, secure coding practices, and conducting research into novel vulnerabilities. My public research includes analysis like **[Weapons of Character](https://github.com/SMCallan/WOC)**, which explores the risks of character-based exploits.

2.  **Digital Strategy & Intelligence**
    * I analyze the strategic landscape of emerging technology to inform decision-making. This includes developing frameworks for understanding hybrid threats and visualizing complex data to reveal underlying trends. My public analyses, such as **[The Convergent Edge](https://smcallan.github.io/secret_states/)** and **[The Chimera Doctrine](https://smcallan.github.io/The-Chimera-Doctrine/)**, are examples of this practice.

3.  **Human-Centric Security & Analysis**
    * Leveraging a foundation in Psychology (BSc) and Computer Science (MSc), I analyze the human element in digital systems. This includes exploring the behavioral economics of market decisions, as demonstrated in the **[Hindsight Trader Pro](https://smcallan.github.io/ChronoVest/)** analysis tool, and understanding the cognitive biases that create vulnerabilities in organizations and individuals.

4.  **Engineering for Intelligence: Code, Systems, and The Law**

* **Software Engineering & Development Methodologies**
-  [Agile LE Tool Development](https://smcallan.github.io/Agile-Law-Enforcement-Tool-Development/)
- [Code as Evidence](https://smcallan.github.io/Code-as-Evidence/)
- [SSDLC](https://smcallan.github.io/SSDLC-Security-Throughout-Development/)
- [Secure Git](https://smcallan.github.io/Version-Control-Strategy-with-Git-for-Sensitive-Projects/)

---
<br>

<details>
<summary><strong>The Digital Crossroads</strong> — My long-form analysis of AI, economics, and society.</summary>
<br>

> *I find myself haunted by a growing certainty that we are living through the convergence of humanity's oldest warnings about technology and power. What I see emerging in our AI-driven world isn't unprecedented—it's the fulfillment of prophecies that philosophers, economists, and social critics have been making for centuries.*

### The Spectre of Alienation
When I watch AI systems generate art that moves me or solve mathematical problems beyond my comprehension, I think of Marx's concept of alienation from the *Economic and Philosophic Manuscripts of 1844*. He warned that when we lose control over our labor and its products, we become estranged from our own humanity. Today, I witness this alienation accelerating as machines don't just replace our physical labor but begin to replicate our creativity, our problem-solving, even our capacity for beauty. The very essence of what we thought made us uniquely human is being commoditized and automated.

### The Prophecies of Scarcity and Purpose
> *"We are being afflicted with a new disease of which some readers may not yet have heard the name, but of which they will hear a great deal in the years to come—namely, technological unemployment."*
>
> — **John Maynard Keynes**, "Economic Possibilities for our Grandchildren" (1930)

Keynes saw this coming nearly a century ago. He predicted that technology would solve scarcity but leave us grappling with purposelessness. I watch young people today questioning whether it's worth developing their talents when an algorithm can outperform them, and I see Keynes' nightmare materializing.

### The Unstoppable Equation of Inequality
The inequality I observe isn't random—it follows the mathematical certainty that Thomas Piketty outlined in *Capital in the Twenty-First Century*. His formula **r > g** (returns on capital exceed economic growth) explains why wealth concentrates naturally. AI accelerates this process exponentially. Those who own the algorithms and data reap returns that dwarf anything previous generations of capitalists could imagine, while the rest of us face what Yuval Noah Harari calls becoming part of a "useless class."

I think often of Adam Smith, so frequently misquoted. In *The Theory of Moral Sentiments*, he warned that commercial society required ethical foundations and that extreme inequality would corrode the social bonds necessary for any functioning economy. I see his fears manifesting as digital platforms, described by Shoshana Zuboff in *The Age of Surveillance Capitalism*, turn our very behaviors and experiences into commodities to be harvested and sold.

### A Path Forward?
Yet I'm not resigned to this trajectory. Elinor Ostrom's Nobel Prize-winning research showed that cooperation can triumph over greed when we design the right institutions. Thinkers like Rutger Bregman propose concrete solutions like universal basic income, while David Graeber's work on "bullshit jobs" suggests we might reimagine work entirely.

What gives me pause is how the behavioral research of Daniel Kahneman and Dan Ariely reveals that our cognitive biases make us vulnerable to exploitative systems. We're predictably irrational in ways that those who design our digital environments understand and manipulate.

Standing at this crossroads, I realize that the question isn't whether technology will transform society—it already has. The question is whether we'll learn from the centuries of wisdom about power, inequality, and human nature that came before us. We have the intellectual framework to build something better. The voices of the past are calling to us, warning us, and showing us the way forward.

The choice, as it has always been, is ours to make.
</details>
